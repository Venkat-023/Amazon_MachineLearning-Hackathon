Unstop ML Hackathon 2025 | Team AVIS | Product Price Prediction | Rank 1693 |Total Registered:82,790 | SMAPE 51.4

#  Amazon Machine Learning Hackathon 2025 â€” Product Price Prediction

This repository contains Team AVISâ€™s solution for the **Unstop ML Hackathon 2025**, where the task was to predict product prices from structured and unstructured catalog data.

ğŸ† Team Name: AVIS
ğŸ“ˆ Final SMAPE: 51.4
ğŸ¥‡ Leaderboard Rank: #1693
âš™ï¸ Frameworks: LightGBM + Sentence Transformers (MiniLM-L6-v2)
ğŸ§  Hardware: GPU-accelerated training on Google Colab

ğŸš€ Project Overview

The goal was to build a regression model that accurately predicts product prices using both structured features (brand, quantity, unit) and unstructured text (titles, bullet points, and product descriptions).

Component	Description
Text Encoder	SentenceTransformer â€“ all-MiniLM-L6-v2
Model	LightGBM (GPU, regression_l1 objective)
Metric	SMAPE (Symmetric Mean Absolute Percentage Error)
Optimization	Early stopping, feature scaling, lemmatization, unit normalization
ğŸ§  Model Architecture

Text Cleaning â€” remove emojis, punctuation, and stopwords

Embedding Generation â€” use SentenceTransformer (MiniLM-L6-v2)

Feature Fusion â€” combine embeddings + categorical + numeric features

Training â€” GPU-based LightGBM regressor

Evaluation â€” SMAPE metric

ğŸ“Š Results
Metric	Score
Validation SMAPE	47.43
Public Leaderboard SMAPE	51.4
Final Rank	#1693 / 84,000
ğŸ§© Tech Stack

ğŸ Python 3.12

ğŸ’¡ LightGBM (GPU)

ğŸ¤– SentenceTransformers (MiniLM-L6-v2)

ğŸ§¹ NLTK for text preprocessing

ğŸ“¦ scikit-learn, pandas, numpy, joblib

ğŸ§ª How to Run
# 1ï¸âƒ£ Install dependencies
!pip install -q lightgbm sentence-transformers emoji nltk

# 2ï¸âƒ£ Run the training script
python amazon_price_prediction.ipynb

# 3ï¸âƒ£ Predict on new data
python inference_script.py --input test.csv --output predicted_prices.csv

ğŸŒŸ Highlights

âœ… Preprocessed 95K+ records combining structured and unstructured data
âœ… Generated 384-dimensional text embeddings using MiniLM
âœ… Optimized LightGBM with GPU acceleration
âœ… Achieved SMAPE 51.4 â€” Top 2% out of 82,790 global participants
